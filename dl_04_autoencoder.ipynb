{"cells":[{"cell_type":"markdown","metadata":{"id":"ilthBvnZCQto"},"source":["# Algorithms for Big Data - Exercise 4\n","This lecture is focused in more detailed understanding of the Convolution neural networks. \n","\n","The visualization and the response of the CNN layers will be intestigated and a proper.\n","\n","We will use the MNIST dataset but other may be used as well.\n"]},{"cell_type":"markdown","metadata":{"id":"Fi2Jwhs35Itq"},"source":["[Open in Google colab](https://colab.research.google.com/github/jplatos/VSB-FEI-Deep-Learning/blob/master/dl_04_autoencoder.ipynb)\n","[Download from Github](https://github.com/jplatos/VSB-FEI-Deep-Learning/blob/master/dl_04_autoencoder.ipynb)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ew-GJJ3Unk_G"},"outputs":[],"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import matplotlib.pyplot as plt # plotting\n","import matplotlib.image as mpimg # images\n","import numpy as np #numpy\n","import tensorflow.compat.v2 as tf #use tensorflow v2 as a main \n","import tensorflow.keras as keras # required for high level applications\n","from sklearn.model_selection import train_test_split # split for validation sets\n","from sklearn.preprocessing import normalize # normalization of the matrix\n","from scipy.signal import convolve2d # convolutionof the 2D signals\n","import scipy\n","import datetime, os\n","\n","tf.version.VERSION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOCGQoBYnk_H"},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fp6mBVVBnk_H"},"outputs":[],"source":["def show_history(history):\n","    plt.figure()\n","    for key in history.history.keys():\n","        plt.plot(history.epoch, history.history[key], label=key)\n","    plt.legend()\n","    plt.tight_layout()\n","\n","def show_example(train_x, train_y, class_names):\n","    plt.figure(figsize=(10,10))\n","    for i in range(25):\n","        plt.subplot(5,5,i+1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        plt.imshow(train_x[i].reshape(28,28), cmap=plt.cm.binary)\n","        plt.xlabel(class_names[train_y[i]])\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIRiUwmSnk_I"},"outputs":[],"source":["class Mish(keras.layers.Activation):\n","    '''\n","    Mish Activation Function.\n","    .. math::\n","        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n","    Shape:\n","        - Input: Arbitrary. Use the keyword argument `input_shape`\n","        (tuple of integers, does not include the samples axis)\n","        when using this layer as the first layer in a model.\n","        - Output: Same shape as the input.\n","    Examples:\n","        >>> X = Activation('Mish', name=\"conv1_act\")(X_input)\n","    '''\n","\n","    def __init__(self, activation, **kwargs):\n","        super(Mish, self).__init__(activation, **kwargs)\n","        self.__name__ = 'Mish'\n","\n","\n","def mish(inputs):\n","    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n","\n","keras.utils.get_custom_objects().update({'mish': Mish(mish)})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AX4m0hoEnk_I"},"outputs":[],"source":["# mnist is the basic dataset for image classifaction\n","dataset = tf.keras.datasets.mnist\n","\n","# data from any dataset are loaded using the load_Data function\n","(train_x, train_y), (test_x, test_y) = dataset.load_data()\n","\n","train_x = train_x.reshape(*train_x.shape, 1)\n","test_x = test_x.reshape(*test_x.shape, 1)\n","\n","train_x = train_x/255.0\n","test_x = test_x/255.0\n","\n","train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n","\n","# the data are in the form of 32x32 pixes with values 0-255.\n","print('Train data shape: ', train_x.shape, train_y.shape)\n","print('Validation data shape: ', valid_x.shape, valid_y.shape)\n","print('Test data shape:  ', test_x.shape, test_y.shape)\n","\n","# class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","class_names = [str(x) for x in range(10)]\n","# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","class_count = len(class_names)\n","print('Class count:', class_count, class_names)\n"]},{"cell_type":"markdown","metadata":{"id":"o9cTfCd_dUYX"},"source":["#### Show example images of the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E__wf-i8CQt0"},"outputs":[],"source":["show_example(train_x, train_y, class_names)"]},{"cell_type":"markdown","metadata":{"id":"omlMtFlgCuTj"},"source":["### Create a well defined model \n","\n","The model is able achieve more the 99% precision on the validation as well as testing sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GqGF8pxYCQt2"},"outputs":[],"source":["model = keras.Sequential([\n","    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","    keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","    keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'),    \n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","    \n","    keras.layers.Flatten(),\n","    keras.layers.Dense(64, activation='relu'),\n","    keras.layers.Dropout(0.25),\n","    keras.layers.Dense(32, activation='relu'),\n","    keras.layers.Dropout(0.25),\n","    keras.layers.Dense(10, activation='softmax'),\n","])\n","\n","model.summary()\n","\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"uz_cLvzw5Iub"},"source":["#### Fit the model on the train data.\n","Lets train the model on the training data and find the best model using the EarlyStopping callback to find the best model avaialble and achievable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcNubiSECQt5"},"outputs":[],"source":["es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, restore_best_weights=True)\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","\n","# batch_size = 32\n","# epochs = 50\n","\n","batch_size = 32\n","epochs = 10\n","history = model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=[es, tensorboard_callback], epochs=epochs, batch_size=batch_size)\n","\n","show_history(history)\n","\n","test_loss, test_acc = model.evaluate(test_x, test_y)\n","print('Test accuracy: ', test_acc)"]},{"cell_type":"markdown","metadata":{"id":"WKQ7znUInk_K"},"source":["## Let's try the tensorboard plugin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8llGsSVnk_K"},"outputs":[],"source":["%tensorboard --logdir logs"]},{"cell_type":"markdown","metadata":{"id":"pCnIUespE4P2"},"source":["## Visualize the layers\n","Lest see what the network was able to learn from the train data. For that, we need to prepare a new model and see the ouputs of the layers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0fMPy-_rdcB"},"outputs":[],"source":["# get the outputs form all layers in the model\n","layer_outputs = [layer.output for layer in model.layers]\n","# create the model that has single input and as an output all the outputs from the layers. \n","# Because the layers are connected then the output from first layer is propagated into second layer and the output is computed o it.\n","activation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n","\n","# get all the outputs from the model for 10-th input\n","activations = activation_model.predict(train_x[10].reshape(1,28,28,1))\n"," \n","# this functions shows the output from each filters\n","def display_activation(activations, col_size, row_size, act_index): \n","    activation = activations[act_index]\n","    activation_index=0\n","    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n","    for row in range(0,row_size):\n","        for col in range(0,col_size):\n","            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n","            activation_index += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qn1tQ1v1ulrj"},"outputs":[],"source":["# show the input image\n","plt.imshow(train_x[10][:,:,0]);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RMEV2Qjpu98v"},"outputs":[],"source":["# show the output from the first layer - CNN2D\n","display_activation(activations, 8, 8, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUWTBNVEvkhk"},"outputs":[],"source":["# show the second convolution layer\n","display_activation(activations, 8, 8, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3rY1W9Jv5cI"},"outputs":[],"source":["# show the third activation layer\n","display_activation(activations, 4, 4, 4)"]},{"cell_type":"markdown","metadata":{"id":"BL5RP5_ELJda"},"source":["## The weights of each layer\n","The weight can be extracted from layer as a tuple of weights and biasses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pMxsTroyYV6"},"outputs":[],"source":["filters, biases = model.layers[0].get_weights()\n","print(filters.shape, biases.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DtRVA3rbLXns"},"outputs":[],"source":["#### The weights may be normalized in to 0-1 interval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wD_ChuZl0oss"},"outputs":[],"source":["f_min, f_max = filters.min(), filters.max()\n","filters = (filters - f_min) / (f_max - f_min)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLxVm4H207Kz"},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","\n","# plot first few filters\n","n_filters = 64\n","for i in range(n_filters):\n","    # get the filter\n","    f = filters[:, :, :, i]\n","    # plot each channel separately\n","    # specify subplot and turn of axis\n","    ax = plt.subplot(8, 8, i+1)\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","    # plot filter channel in grayscale\n","    plt.imshow(f[:, :, 0], cmap='gray')\n","  \n","# show the figure\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"tGJ5tWyS3_TQ"},"source":["## Autoencoder\n","The autoencoder is a special type of neural network that is able to learn without the classes just from the input data. It is equivalent to the feature extraction from the data.\n","\n","It's worth a mention that we are using binary crossentropy loss, thus we compare images on per-pixel basis.\n","- You can view [this link](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a) for more information about Bin. CE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QuVpJVK94DFp"},"outputs":[],"source":["autoencoder = keras.Sequential([\n","    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","    keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","    keras.layers.Conv2D(8, (3,3), padding='same', activation='relu'),    \n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","    # a 128 values of the minimized knowledge / features\n","    keras.layers.Conv2D(8, (3,3), padding='same', activation='relu'),\n","    keras.layers.UpSampling2D((2,2)),\n","    keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n","    keras.layers.UpSampling2D((2,2)),\n","    keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    keras.layers.UpSampling2D((2,2)),\n","    \n","    keras.layers.Conv2D(1, (3,3), activation='sigmoid', padding='same')\n","])\n","\n","autoencoder.summary()\n","\n","autoencoder.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"qWU9bNYvEj0B"},"source":["### Fit the model\n","The model may be fitted as much as possible, this model converges but slowly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTlUF95g74Ix"},"outputs":[],"source":["history = autoencoder.fit(train_x, train_x, validation_data=(valid_x, valid_x), epochs=10, batch_size=128)\n","\n","show_history(history)"]},{"cell_type":"markdown","metadata":{"id":"H-t0IRJqGSh3"},"source":["### Generate original and reconstructed images\n","The autoencoder fits on the original data on input as well as on output, therefore it is possible to generate reconstructed images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B13tGF3soCGg"},"outputs":[],"source":["predicted = autoencoder.predict(test_x)\n","\n","n = 10\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    # display original\n","    ax = plt.subplot(2, n, i+1)\n","    plt.imshow(test_x[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # display reconstruction\n","    ax = plt.subplot(2, n, i + 1+n)\n","    plt.imshow(predicted[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"FW3TBKwrHPHj"},"source":["### Vizualize the encoded vectors\n","The vectors that are generated by the encoder may be vizualized."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bc9Gwgg6pj5-"},"outputs":[],"source":["encoder = keras.Sequential([\n","    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","    keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","    keras.layers.Conv2D(8, (3,3), padding='same', activation='relu'),    \n","    keras.layers.MaxPooling2D((2, 2), padding='same'),\n","])\n","\n","# encoder.compile(optimizer='adam', loss='binary_crossentropy')\n","encoder.set_weights(autoencoder.get_weights()[:6])\n","\n","for layer in encoder.layers:\n","  layer.trainable = False\n","\n","encoder.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2AKBMZqop2J"},"outputs":[],"source":["encoded = encoder.predict(test_x)\n","\n","n = 10\n","plt.figure(figsize=(20, 8))\n","for i in range(n):\n","    ax = plt.subplot(2, n, i+1)\n","    plt.imshow(encoded[i].reshape(8, 16).T)\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    \n","    ax = plt.subplot(2, n, n+i+1)\n","    plt.imshow(test_x[i].reshape(28,28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"D8D6okcRKNGr"},"source":["### Is the encoder-based classifier better than the previous one above?\n","The encoder generated using the autoencoder principle generate a compressed representation of the input. The inner vector with 128 values is much smaller and the goal of the autoencoder is different than from the classifier, therefore the generated representation is usually better using the classifier directly.\n","Some variants of encoder are able to generate better representation - a sparse autoencoders that generate sparse representation for example.\n","\n","### Is it possible to control how sparse our representation will be? If it's possible, what method would you use? [API](https://keras.io/api/layers/regularizers/)\n","\n","### Why is it usually better to use classifier directly and not train encoder for feature extraction first and then put classification layers on top of it? "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17_ESVZavDRH"},"outputs":[],"source":["\n","encoder.add(keras.layers.Flatten())\n","encoder.add(keras.layers.Dense(64, activation='relu'))\n","encoder.add(keras.layers.Dropout(0.25))\n","encoder.add(keras.layers.Dense(32, activation='relu'))\n","encoder.add(keras.layers.Dropout(0.25))\n","encoder.add(keras.layers.Dense(10, activation='softmax'))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v1XCcy80ASJq"},"outputs":[],"source":["encoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n","encoder.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDKSZrl6wII7"},"outputs":[],"source":["es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, restore_best_weights=True)\n","\n","history = encoder.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks = [es], epochs=10)\n","\n","show_history(history)\n","\n","test_loss, test_acc = encoder.evaluate(test_x, test_y)\n","print('Test accuracy: ', test_acc)"]},{"cell_type":"markdown","metadata":{"id":"88jmOJ04nk_N"},"source":["## Outlier analysis\n","Let use the autoencoder as an outlier analyzer. \n","\n","First, prepare the testing set. then create a outlier data and compare the prediction error on the both."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UM21PKJbnk_N"},"outputs":[],"source":["sample_x = test_x[:25]\n","sample_y = test_y[:25]\n","\n","show_example(sample_x, sample_y, class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Bb-pKhmnk_N"},"outputs":[],"source":["modified_x = np.clip(sample_x + 0.1 * np.random.normal(loc=0.0, scale=1.0, size=sample_x.shape), 0., 1.) \n","modified_y = sample_y\n","show_example(modified_x, modified_y, class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1sIJXsKnk_O"},"outputs":[],"source":["sample_predicted = autoencoder.predict(sample_x)\n","show_example(sample_predicted, sample_y, class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6e4JTFrnk_O"},"outputs":[],"source":["modified_pred = autoencoder.predict(modified_x)\n","show_example(modified_pred, modified_y, class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJ2WA6sdnk_O"},"outputs":[],"source":["# https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n","# np.linalg.norm -> Frobenius norm ~ root of squared errors\n","\n","sample_norms = [np.linalg.norm(sample_x[i].reshape(28,28)- sample_predicted[i].reshape(28,28)) for i in range(len(sample_x))]\n","modified_norms = [np.linalg.norm(modified_x[i].reshape(28,28)- modified_pred[i].reshape(28,28)) for i in range(len(sample_x))]\n","\n","sample_mean, sample_std = np.mean(sample_norms), np.std(sample_norms)\n","modified_mean, modified_std = np.mean(modified_norms), np.std(modified_norms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nP2MoOLxnk_O"},"outputs":[],"source":["plt.figure(figsize=(16,9))\n","xmin = np.min([sample_mean-4*sample_std, modified_mean-4*modified_std])\n","xmax = np.max([sample_mean+4*sample_std, modified_mean+4*modified_std])\n","\n","x = np.linspace(xmin, xmax, 100)\n","\n","y = scipy.stats.norm.pdf(x,sample_mean,sample_std)\n","\n","plt.plot(x,y)\n","\n","y = scipy.stats.norm.pdf(x,modified_mean,modified_std)\n","\n","plt.plot(x,y)\n","\n","plt.bar(x=sample_norms, height=[0.6 for x in sample_norms], width=0.01)\n","plt.bar(x=modified_norms, height=[0.6 for x in sample_norms], width=0.01)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TnnRMaEcPi1w"},"source":["## Denoising-autoencoder\n","The denoising autoencoder is a autoencoder that will learn how to remove random noise from the images. \n","\n","First, noisy images have to be generated. \n","\n","Then the autoencoder need to be created and trained. \n","\n","Then denosed images may be reconstructed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VSzOFCOnk_O"},"outputs":[],"source":["noise_factor = 0.5\n","noisy_train_x = np.clip(train_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_x.shape), 0., 1.)\n","noisy_valid_x = np.clip(valid_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=valid_x.shape), 0., 1.)\n","noisy_test_x = np.clip(test_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_x.shape), 0., 1.) \n","\n","\n","n = 10\n","plt.figure(figsize=(2*n, 4))\n","for i in range(n):\n","    ax = plt.subplot(2, n, i+1)\n","    plt.imshow(train_x[i].reshape(28,28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    \n","    ax = plt.subplot(2, n, n+i+1)\n","    plt.imshow(noisy_train_x[i].reshape(28,28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"myIgGem85IvT"},"source":["## Tasks for Lecture / Exercise\n","1. Implement the autoencoder that do something usefull like denoising, implement it on the data defined above.\n","2. The Keras contains stored models that may be used for classification. The pretrained models may be used effectivelly to classify data, e.g. images, using the state of the art models. Try to investigate the architecture of the stored models and use the for classification of sample data downloaded from the internet.\n","  1. Try VGG16 model and investigrate its architecture.\n","  2. Try ResNet model architecture.\n","- See [Keras Functional API](https://keras.io/guides/functional_api/)\n","- See [this for VGG16 and ResNet fine tuning](https://keras.io/api/applications/), chapter Fine-tune InceptionV3 on a new set of classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZqjOH_C3nk_O"},"outputs":[],"source":["from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLiPsZIank_O"},"outputs":[],"source":["def grayscale_to_rgb(images, channel_axis=-1):\n","    # images= keras.backend.expand_dims(images, axis=channel_axis)\n","    tiling = [1] * 4    # 4 dimensions: B, H, W, C\n","    tiling[channel_axis] *= 3\n","    images= keras.backend.tile(images, tiling)\n","    return images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9YWZC0Jnk_O"},"outputs":[],"source":["size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"98ImZ35qnk_O"},"outputs":[],"source":["train_x_res = np.array([cv2.resize(x, (size, size)) for x in train_x])\n","test_x_res = np.array([cv2.resize(x, (size, size)) for x in test_x])\n","valid_x_res = np.array([cv2.resize(x, (size, size)) for x in valid_x])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqhcklfCnk_O"},"outputs":[],"source":["train_x_r = train_x_res.reshape(-1, size, size, 1).astype('float32')\n","test_x_r = test_x_res.reshape(-1, size, size, 1).astype('float32')\n","valid_x_r = valid_x_res.reshape(-1, size, size, 1).astype('float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87jlwW-jnk_O"},"outputs":[],"source":["train_x_r = grayscale_to_rgb(train_x_r)\n","test_x_r = grayscale_to_rgb(test_x_r)\n","valid_x_r = grayscale_to_rgb(valid_x_r)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"file_extension":".py","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat":4,"nbformat_minor":0}
